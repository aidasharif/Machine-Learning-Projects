{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6140 Assignments\n",
    "\n",
    "**Instructions**\n",
    "1. In each assignment cell, look for the block:\n",
    " ```\n",
    "  #BEGIN YOUR CODE\n",
    "  raise NotImplementedError.new()\n",
    "  #END YOUR CODE\n",
    " ```\n",
    "1. Replace this block with your solution.\n",
    "1. Test your solution by running the cells following your block (indicated by ##TEST##)\n",
    "1. Click the \"Validate\" button above to validate the work.\n",
    "\n",
    "**Notes**\n",
    "* You may add other cells and functions as needed\n",
    "* Keep all code in the same notebook\n",
    "* In order to receive credit, code must \"Validate\" on the JupyterHub server\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68dd2ebeee2a443f256c9a86cf6a02c3",
     "grade": false,
     "grade_id": "cell-2db1ec9fd61f5d6b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Final Project: Part 2 - Feature Extraction\n",
    "\n",
    "\n",
    "In any practical machine learning problem, the data preparation and feature extraction stages are the most important and time-consuming. The final project exposes you to a real-world dataset. In this part of the final project, you will implement various feature extraction and transformation methods that will be useful in the next part. \n",
    "\n",
    "There is an accompanying notebook, [part-2-a](../part-2-a.ipynb) which illustrates the feature extraction methods in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edd3092e2281962577b174d0a70b6ec4",
     "grade": false,
     "grade_id": "cell-af1d85683fc29192",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if(window['d3'] === undefined ||\n",
       "   window['Nyaplot'] === undefined){\n",
       "    var path = {\"d3\":\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\",\"downloadable\":\"http://cdn.rawgit.com/domitry/d3-downloadable/master/d3-downloadable\"};\n",
       "\n",
       "\n",
       "\n",
       "    var shim = {\"d3\":{\"exports\":\"d3\"},\"downloadable\":{\"exports\":\"downloadable\"}};\n",
       "\n",
       "    require.config({paths: path, shim:shim});\n",
       "\n",
       "\n",
       "require(['d3'], function(d3){window['d3']=d3;console.log('finished loading d3');require(['downloadable'], function(downloadable){window['downloadable']=downloadable;console.log('finished loading downloadable');\n",
       "\n",
       "\tvar script = d3.select(\"head\")\n",
       "\t    .append(\"script\")\n",
       "\t    .attr(\"src\", \"http://cdn.rawgit.com/domitry/Nyaplotjs/master/release/nyaplot.js\")\n",
       "\t    .attr(\"async\", true);\n",
       "\n",
       "\tscript[0][0].onload = script[0][0].onreadystatechange = function(){\n",
       "\n",
       "\n",
       "\t    var event = document.createEvent(\"HTMLEvents\");\n",
       "\t    event.initEvent(\"load_nyaplot\",false,false);\n",
       "\t    window.dispatchEvent(event);\n",
       "\t    console.log('Finished loading Nyaplotjs');\n",
       "\n",
       "\t};\n",
       "\n",
       "\n",
       "});});\n",
       "}\n"
      ],
      "text/plain": [
       "\"if(window['d3'] === undefined ||\\n   window['Nyaplot'] === undefined){\\n    var path = {\\\"d3\\\":\\\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\\\",\\\"downloadable\\\":\\\"http://cdn.rawgit.com/domitry/d3-downloadable/master/d3-downloadable\\\"};\\n\\n\\n\\n    var shim = {\\\"d3\\\":{\\\"exports\\\":\\\"d3\\\"},\\\"downloadable\\\":{\\\"exports\\\":\\\"downloadable\\\"}};\\n\\n    require.config({paths: path, shim:shim});\\n\\n\\nrequire(['d3'], function(d3){window['d3']=d3;console.log('finished loading d3');require(['downloadable'], function(downloadable){window['downloadable']=downloadable;console.log('finished loading downloadable');\\n\\n\\tvar script = d3.select(\\\"head\\\")\\n\\t    .append(\\\"script\\\")\\n\\t    .attr(\\\"src\\\", \\\"http://cdn.rawgit.com/domitry/Nyaplotjs/master/release/nyaplot.js\\\")\\n\\t    .attr(\\\"async\\\", true);\\n\\n\\tscript[0][0].onload = script[0][0].onreadystatechange = function(){\\n\\n\\n\\t    var event = document.createEvent(\\\"HTMLEvents\\\");\\n\\t    event.initEvent(\\\"load_nyaplot\\\",false,false);\\n\\t    window.dispatchEvent(event);\\n\\t    console.log('Finished loading Nyaplotjs');\\n\\n\\t};\\n\\n\\n});});\\n}\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "#<SQLite3::Database:0x000000000276ce68 @tracefunc=nil, @authorizer=nil, @encoding=nil, @busy_handler=nil, @collations={}, @functions={}, @results_as_hash=true, @type_translation=nil, @type_translator=#<Proc:0x000000000267c7d8@/usr/local/rvm/gems/ruby-2.5.1/gems/sqlite3-1.4.2/lib/sqlite3/database.rb:722 (lambda)>, @readonly=true>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require './assignment_lib'\n",
    "\n",
    "#Initializes the database used for this assignment\n",
    "dir = \"/home/dataset\"\n",
    "$dev_db = SQLite3::Database.new \"#{dir}/credit_risk_data_dev.db\", results_as_hash: true, readonly: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7587eda446bac1f567330e55b7296baa",
     "grade": false,
     "grade_id": "cell-813bedaa91a4a36a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Create Dataset\n",
    "\n",
    "The function ```create_dataset``` has been implemented for you in [assignment_lib.rb](../assignment_lib.rb). Given an SQL query, this function constructs the examples for a dataset like those we have used in this course. \n",
    "\n",
    "An ```id``` field is added for each example, equal to the ```SK_ID_CURR``` and the ```TARGET``` is called ```label```. These fields **must** be in the query. All feature names from the SQL query are lowercased in the features field. \n",
    "\n",
    "\n",
    "If the query is:\n",
    "```sql\n",
    "select sk_id_curr, target, ext_source_1 from application_train  where ext_source_1 <> '' order by sk_id_curr;\n",
    "```\n",
    "\n",
    "then the result is:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"features\" : [\"ext_source_1\"],\n",
    "    \"data\" : [\n",
    "        {\"label\":1,\"id\":100002,\"features\":{\"ext_source_1\":0.08303696739132256}},\n",
    "        {\"label\":0,\"id\":100015,\"features\":{\"ext_source_1\":0.7220444501416448}}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e96c32b88a8e6b24dd364f4ddbc78803",
     "grade": false,
     "grade_id": "cell-8688ed35b3c26d22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"features\"=>[\"ext_source_1\"], \"data\"=>[{\"label\"=>1, \"id\"=>100002, \"features\"=>{\"ext_source_1\"=>0.08303696739132256}}]}\n"
     ]
    }
   ],
   "source": [
    "sql = <<SQL\n",
    "select sk_id_curr, target, ext_source_1 \n",
    "from application_train \n",
    "where ext_source_1 <> '' \n",
    "order by sk_id_curr limit 1\n",
    "SQL\n",
    "  \n",
    "dataset = create_dataset $dev_db, sql\n",
    "examples = dataset[\"data\"]  \n",
    "puts dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4783d5870031d00fc706ff9ad7ba235",
     "grade": false,
     "grade_id": "cell-d6effdf0e0d425da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Sample dataset\n",
    "Here is a sample dataset we will use in this part, which illustrates some basic feature extraction. Note that this is just an example and you **should not** restrict your final project to these features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "625cf829f7b6fa0860f1107659ce5989",
     "grade": false,
     "grade_id": "cell-e741e443c7ebcec9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":create_sample_dataset"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a sample datasete and store as a separate file\n",
    "def create_sample_dataset\n",
    "  sql = <<SQL\n",
    "  select target\n",
    ", sk_id_curr\n",
    ", ext_source_1\n",
    ", ext_source_2\n",
    ", ext_source_3\n",
    ", amt_income_total\n",
    ", amt_credit\n",
    ", commonarea_avg\n",
    ", flag_own_car \n",
    ", flag_mobil\n",
    ", days_birth\n",
    ", organization_type\n",
    ", code_gender\n",
    ", flag_own_realty\n",
    ", flag_emp_phone\n",
    ", name_education_type\n",
    ", name_income_type\n",
    ", name_family_status\n",
    ", name_housing_type\n",
    ", own_car_age\n",
    "from application_train\n",
    "where ext_source_1 <> ''\n",
    "order by sk_id_curr\n",
    "SQL\n",
    "\n",
    "  sample_dataset = create_dataset $dev_db, sql\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c9c54cc9af602f240c8f73f27b6e350",
     "grade": false,
     "grade_id": "cell-a9c035c5ee0c61be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Export dataset\n",
    "\n",
    "The ```export_to_tsv``` function below exports a datset into TSV file that can be read by R or Excel. If you so choose, you can use this to export any features you have for use in R, see related notebook. We will export the sample dataset to ```part-2-sample.tsv``` in this directory if you want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c26ca3891aebb3fba0e7eedfd489b8b9",
     "grade": false,
     "grade_id": "cell-308d33ba92423d74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":export_to_tsv"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def export_to_tsv dataset, file_name\n",
    "  File.open file_name, 'w' do |out|\n",
    "    features = dataset[\"features\"].sort\n",
    "    out.puts [[\"id\", \"label\"], features].join(\"\\t\")\n",
    "    examples = dataset[\"data\"]\n",
    "    \n",
    "    examples.each do |example|\n",
    "      id = example[\"id\"]\n",
    "      label = example[\"label\"]\n",
    "      values = features.collect {|k| example[\"features\"].fetch(k, nil)}\n",
    "      out.puts [id, label, values].join(\"\\t\")\n",
    "    end.size\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6937d34eb336a9475726c90052079725",
     "grade": false,
     "grade_id": "cell-b4ae018cd72161e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6641"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def export_sample_dataset\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  export_to_tsv sample_dataset, \"./part-2-random-sample.tsv\"\n",
    "end\n",
    "\n",
    "## The line below should return 6641 examples\n",
    "export_sample_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57501e4626244845a46026fef61a5b43",
     "grade": false,
     "grade_id": "cell-21e1ebb3f120c4dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1.1 (4 points)\n",
    "\n",
    "Given an array of doubles, ```x```, implement mean and the sample standard deviation (not the population standard deviation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "923527affef5d287917624bdd67f6bf3",
     "grade": false,
     "grade_id": "cell-b553c2fec04a33f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":mean"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean x\n",
    "  sum=0\n",
    "  x.each do |item|\n",
    "    sum+=item.to_f\n",
    "  end\n",
    "  \n",
    "  return sum.to_f/(x.size)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eff36470700acee42454fccb7f8784ec",
     "grade": true,
     "grade_id": "cell-e3a374b64a13c4de",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST ###\n",
    "def test_11_0()\n",
    "  test_1 = [3.0, 4.0, 5.0]\n",
    "  assert_equal(4.0, mean(test_1))\n",
    "end\n",
    "test_11_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a584827614002544e6344c5a299348fb",
     "grade": false,
     "grade_id": "cell-46c6c3bdb02e8d60",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":stdev"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stdev x\n",
    "  sum=0\n",
    "  mean1=mean(x)\n",
    "  #puts mean1\n",
    "  x.each do |item|\n",
    "    sum+=(item-mean1)**2\n",
    "  end\n",
    "  \n",
    "  #puts sum\n",
    "  \n",
    "  return (sum.to_f/(x.size-1))**0.5\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc703679757dc7be13ab7e14bb0f0f1c",
     "grade": true,
     "grade_id": "cell-c5e91d25f46794d4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### TEST ###\n",
    "def test_12_1()\n",
    "  test_1 = [3.0, 4.0, 5.0]\n",
    "  assert_equal(1.0, stdev(test_1))\n",
    "end\n",
    "test_12_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c3b9e2c1972c531d7cd6a9c958aea91",
     "grade": false,
     "grade_id": "cell-500015f428142cc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "We will adopt a __Pipeline__ software development pattern for feature extraction in which a ```FeatureTransformer``` is first trained on the dataset and then applied to a batch of examples. \n",
    "\n",
    "```ruby\n",
    "class FeatureTransformer\n",
    "    def train dataset\n",
    "        ## Calculate any statistics\n",
    "    end\n",
    "    \n",
    "    def apply example_batch\n",
    "        ## Apply transform to a batch of examples\n",
    "    end\n",
    "end\n",
    "```\n",
    "\n",
    "You will create multiple ```FeatureTransformers``` which will alter a dataset and are designed to be used sequentially. Each transform will be trained with data to collect any statistics and then will transform a batch of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1 (5 points)\n",
    "\n",
    "Implement the Z-Score Transformer. We have implemented z-score normalization before, but this is a refactor as a FeatureTransformer.\n",
    "\n",
    "In the ```train``` method, calculate the ```means``` and ```stdevs``` member hashes containing the mean and standard deviation for the list of features provided in ```@whitelist```. \n",
    "\n",
    "Example:\n",
    "```\n",
    "Means\n",
    "{\"ext_source_1\"=>0.4977204432348777, \"ext_source_2\"=>0.5264289029370367}\n",
    "\n",
    "Stdevs\n",
    "{\"ext_source_1\"=>0.21195635191237827, \"ext_source_2\"=>0.18333559581081152}\n",
    "```\n",
    "\n",
    "1. Do not alter the data in train method\n",
    "1. If the feature is missing i.e., ```nil```, do not accumulate it. Don't assume it has a value. We will deal with missing values later.\n",
    "1. Expect that this method will be called with string-valued features, do not accumulate them either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c94a515d5d1ea211ddf56c3d522974da",
     "grade": false,
     "grade_id": "cell-81db567561a8b3d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":train"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ZScoreTransformer\n",
    "  attr_reader :means, :stdevs\n",
    "  \n",
    "  def initialize feature_names\n",
    "    @means = Hash.new {|h,k| h[k] = 0}\n",
    "    @miss = Hash.new {|h,k| h[k] = 0}\n",
    "    @stdevs = Hash.new {|h,k| h[k] = 0}\n",
    "    @feature_names = feature_names    \n",
    "  end\n",
    "  \n",
    "  def train dataset\n",
    "    \n",
    "    data=dataset[\"data\"]\n",
    "    \n",
    "    @feature_names.each do |feature|\n",
    "      data.each do |item|\n",
    "        if item[\"features\"][feature]==nil\n",
    "          @miss[feature]=@miss[feature]+1\n",
    "        end\n",
    "        next if !(item[\"features\"][feature].is_a?(Numeric))\n",
    "      end\n",
    "    end \n",
    "        \n",
    "    @feature_names.each do |feature|\n",
    "      data.each do |item|\n",
    "        next if item[\"features\"][feature]==nil\n",
    "        next if !(item[\"features\"][feature].is_a?(Numeric))\n",
    "        @means[feature]=(item[\"features\"][feature]).to_f+@means[feature]\n",
    "      end\n",
    "    end\n",
    "    \n",
    "\n",
    "    @means.each do |key,array|\n",
    "      @means[key]=(@means[key]).to_f/(data.size-@miss[key]).to_f\n",
    "    end\n",
    "\n",
    "\n",
    "    @feature_names.each do |feature|\n",
    "      data.each do |item2|\n",
    "        next if !item2[\"features\"][feature]\n",
    "        next if !(item2[\"features\"][feature].is_a?(Numeric))\n",
    "        @stdevs[feature]+=(item2[\"features\"][feature]-@means[feature])**2\n",
    "      end\n",
    "      \n",
    "      @stdevs[feature]=((@stdevs[feature]).to_f/(data.size-@miss[feature]-1))**0.5\n",
    "    end\n",
    "    \n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcfdb22cbfc0bda5135708285355e4b0",
     "grade": true,
     "grade_id": "cell-a35185310e229525",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means\n",
      "{\"ext_source_1\"=>0.4977204432348777, \"ext_source_2\"=>0.5264289029370367}\n"
     ]
    }
   ],
   "source": [
    "def test_21_1()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  whitelist = %w(ext_source_1 ext_source_2)\n",
    "  \n",
    "  zscore = ZScoreTransformer.new whitelist\n",
    "  zscore.train sample_dataset\n",
    "  z_means = zscore.means\n",
    "  puts \"Means\", z_means\n",
    "  \n",
    "  assert_equal whitelist.size, z_means.size\n",
    "  \n",
    "  assert_in_delta(0.4977204432348777, zscore.means[\"ext_source_1\"], 1e-2, \"Mean for ext_source_1\")\n",
    "  assert_in_delta(0.5258740162753052, zscore.means[\"ext_source_2\"], 1e-2, \"Mean for ext_source_2\")\n",
    "end\n",
    "\n",
    "test_21_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "572e7fbbe80fa263b63a7cd85ce25567",
     "grade": true,
     "grade_id": "cell-ed6d2cdf464d26a1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stdevs\n",
      "{\"ext_source_1\"=>0.21195635191237827, \"ext_source_2\"=>0.18333559581081152}\n"
     ]
    }
   ],
   "source": [
    "def test_21_2()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  whitelist = %w(ext_source_1 ext_source_2)\n",
    "  \n",
    "  zscore = ZScoreTransformer.new whitelist\n",
    "  zscore.train sample_dataset\n",
    "  \n",
    "  z_stdevs = zscore.stdevs\n",
    "  puts \"Stdevs\", z_stdevs\n",
    "  \n",
    "  assert_equal whitelist.size, z_stdevs.size\n",
    "  \n",
    "  assert_in_delta(0.21195635191237827, zscore.stdevs[\"ext_source_1\"], 1e-2, \"Stdev for ext_source_1\")\n",
    "  assert_in_delta(0.18403355900410537, zscore.stdevs[\"ext_source_2\"], 1e-2, \"Stdev for ext_source_2\")\n",
    "end\n",
    "\n",
    "test_21_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a2159312255523c1cca73a5f4912aba",
     "grade": true,
     "grade_id": "cell-f4c7c993397d9cdb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_21_3()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  \n",
    "  ## Added a string-valued feature, check that it does not cause any problems\n",
    "  whitelist = %w(ext_source_1 ext_source_2 code_gender)\n",
    "  \n",
    "  zscore = ZScoreTransformer.new whitelist\n",
    "  zscore.train sample_dataset\n",
    "  \n",
    "  assert_false(zscore.means.has_key?(\"ext_source_3\"), \"Only apply to whitelisted features\")\n",
    "end\n",
    "\n",
    "test_21_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63a4793691334091d4d9e6bcaed48d08",
     "grade": false,
     "grade_id": "cell-fc9484dff8b0b0a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, implement the ```apply``` method, which takes a batch of examples and applies the z-normalization (aka standardization). Examples are altered in place without copying. Note that any feature which is missing or has zero standard deviation should not be altered. \n",
    "\n",
    "Transform should alter features in place, for example:\n",
    "```\n",
    "Before transform:\n",
    "[{\"features\"=>{\"ext_source_1\"=>0.08303696739132256}}]\n",
    "After transform:\n",
    "[{\"features\"=>{\"ext_source_1\"=>-1.956456940790259}}]\n",
    "```\n",
    "\n",
    "Note:\n",
    "1. Skip any missing features. We could assume they are zero, but we will not do this here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05fe5082155f69708cc79d379575ac20",
     "grade": false,
     "grade_id": "cell-3e04c2037a7b2814",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":apply"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ZScoreTransformer  \n",
    "  def apply example_batch\n",
    "    \n",
    "    example_batch.each do |item|\n",
    "      item[\"features\"].each do |key,array|\n",
    "        next if !item[\"features\"][key] or @stdevs[key]==0 or !(@feature_names.include? key)\n",
    "        break if !(item[\"features\"][key].is_a?(Numeric))\n",
    "        item[\"features\"][key]=(item[\"features\"][key]-@means[key])/(@stdevs[key])\n",
    "      end\n",
    "    end\n",
    "\n",
    "    return example_batch\n",
    "  end\n",
    "end\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbd8fb4638df06ee0856df1f0dae5644",
     "grade": true,
     "grade_id": "cell-e7bee13f50f4e101",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transform:\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.08303696739132256}}]\n",
      "After transform:\n",
      "[{\"features\"=>{\"ext_source_1\"=>-1.956456940790259}}]\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "def test_21_4()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  whitelist = %w(ext_source_1 ext_source_2 code_gender)\n",
    "  \n",
    "  zscore = ZScoreTransformer.new whitelist\n",
    "  example1 = {\"features\" => {\"ext_source_1\" => 0.08303696739132256}}\n",
    "  example_batch = [example1]\n",
    "\n",
    "  puts \"Before transform:\", example_batch\n",
    "  zscore.train sample_dataset\n",
    "  assert_in_delta(0.08303696739132256, example1[\"features\"][\"ext_source_1\"], 1e-3, \"Creating transform does not alter dataset\")\n",
    "  \n",
    "  zscore.apply(example_batch)\n",
    "  puts \"After transform:\", example_batch\n",
    "\n",
    "  assert_in_delta(-1.956456940790259, example1[\"features\"][\"ext_source_1\"], 1e-3, \"Applies to ext_source_1\")\n",
    "end\n",
    "\n",
    "test_21_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "664c564d655236748d4d6aa5cdb18809",
     "grade": true,
     "grade_id": "cell-43f6a1b02d477a00",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transform:\n",
      "[{\"features\"=>{\"name_education_type\"=>\"Secondary / secondary special\", \"code_gender\"=>\"M\"}}]\n",
      "After transform:\n",
      "[{\"features\"=>{\"name_education_type\"=>\"Secondary / secondary special\", \"code_gender\"=>\"M\"}}]\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "# Handles string-valued features\n",
    "\n",
    "def test_21_5()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  whitelist = %w(code_gender)\n",
    "  zscore = ZScoreTransformer.new whitelist\n",
    "  zscore.train sample_dataset\n",
    "  \n",
    "  example1 = {\"features\" => {\"name_education_type\" => \"Secondary / secondary special\", \"code_gender\" => \"M\"}}\n",
    "  example_batch = [example1]\n",
    "  \n",
    "  puts \"Before transform:\", example_batch\n",
    "  zscore.apply(example_batch)\n",
    "  puts \"After transform:\", example_batch\n",
    "\n",
    "  assert_equal(\"Secondary / secondary special\", example1[\"features\"][\"name_education_type\"], \"Skips features not in whitelist\")\n",
    "  assert_equal(\"M\", example1[\"features\"][\"code_gender\"], \"Does not apply to features with zero stdev\")  \n",
    "end\n",
    "\n",
    "test_21_5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e2cc56c7ff836dbd761f86832287c77",
     "grade": false,
     "grade_id": "cell-e847a309438a46c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2.2 (10 points)\n",
    "\n",
    "Implement the mean imputation transform any example with a missing feature has that feature replaced with the mean of the non-missing feature values. Note that this only makes sense for numeric features. The transformer takes an array of feature names as a whitelist. \n",
    "\n",
    "In the ```train``` method, calculate the mean values for each whitelisted feature. Store these means in the ```means``` member variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dd33d3c09a698795f3daaf4c6f652ab",
     "grade": false,
     "grade_id": "cell-069d2908c33c3313",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":train"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MeanImputation\n",
    "  attr_reader :means\n",
    "  \n",
    "  def initialize feature_names\n",
    "    @means = Hash.new {|h,k| h[k] = 0}\n",
    "    @miss = Hash.new {|h,k| h[k] = 0}\n",
    "    @feature_names = feature_names \n",
    "  end\n",
    "  \n",
    "  def train dataset    \n",
    "    data=dataset[\"data\"]\n",
    "\n",
    "    @feature_names.each do |feature|\n",
    "      mean=[]\n",
    "      data.each do |item|\n",
    "        next if item[\"features\"][feature].nil?\n",
    "        next if !(item[\"features\"][feature].is_a? Numeric)\n",
    "        mean << item[\"features\"][feature]           \n",
    "      end\n",
    "      @means[feature] = mean(mean)\n",
    "    end\n",
    "    \n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5eecd8988bbfc0a3f87e364982c880a",
     "grade": true,
     "grade_id": "cell-8744e34221a0bb4e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means\n",
      "{\"ext_source_2\"=>0.5264289029370367}\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "def test_22_1()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  whitelist = %w(ext_source_2)\n",
    "  transform = MeanImputation.new whitelist\n",
    "  transform.train sample_dataset\n",
    "  z_means = transform.means\n",
    "  puts \"Means\", z_means\n",
    "  \n",
    "  assert_equal whitelist.size, z_means.size  \n",
    "  assert_false(z_means.has_key?(\"ext_source_3\"), \"Only apply to whitelisted features\")  \n",
    "  assert_in_delta(0.5258740162753052, z_means[\"ext_source_2\"], 1e-2, \"Mean for ext_source_2\")\n",
    "end\n",
    "\n",
    "test_22_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22ad2ae12f279c1b56a1fe8eb75400b2",
     "grade": false,
     "grade_id": "cell-5608b45be3062d64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, implement the ```apply``` method in which we replace missing values with the mean available in the ```@means``` member variable. Examples are altered in place.\n",
    "\n",
    "Example:\n",
    "```\n",
    "Before imputation\n",
    "[{\"features\"=>{\"ext_source_2\"=>nil}}]\n",
    "After imputation\n",
    "[{\"features\"=>{\"ext_source_2\"=>0.5264289029370367}}]\n",
    "```\n",
    "\n",
    "Notes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b0844ef70cae0ed0cf4659a6167705a",
     "grade": false,
     "grade_id": "cell-cfd5b9a00e7324fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":apply"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MeanImputation  \n",
    "  def apply(example_batch)\n",
    "        \n",
    "    example_batch.each do |item|\n",
    "      @feature_names.each do |feature|\n",
    "        if item[\"features\"][feature]==nil and @means[feature].is_a? (Numeric)\n",
    "          item[\"features\"][feature]=@means[feature]\n",
    "        end\n",
    "      end\n",
    "    end  \n",
    "    return example_batch\n",
    "    \n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53d3103045b0a6333e9b8e9e20fb1b26",
     "grade": true,
     "grade_id": "cell-c164b9fa8f6cf8bc",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means\n",
      "{\"ext_source_2\"=>0.5264289029370367}\n",
      "Before imputation\n",
      "[{\"features\"=>{\"ext_source_2\"=>nil}}, {\"features\"=>{\"ext_source_1\"=>0.12345}}]\n",
      "After imputation\n",
      "[{\"features\"=>{\"ext_source_2\"=>0.5264289029370367}}, {\"features\"=>{\"ext_source_1\"=>0.12345, \"ext_source_2\"=>0.5264289029370367}}]\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "# Verifies that transformer calculates means for non-missing values\n",
    "def test_22_2()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  whitelist = %w(ext_source_2)\n",
    "  transform = MeanImputation.new whitelist\n",
    "  \n",
    "  transform.train sample_dataset\n",
    "  z_means = transform.means\n",
    "  puts \"Means\", z_means\n",
    "  \n",
    "  example1 = {\"features\" => {\"ext_source_2\" => nil}}\n",
    "  example2 = {\"features\" => {\"ext_source_1\" => 0.12345}}\n",
    "  \n",
    "  batch = [example1, example2]\n",
    "  \n",
    "  puts \"Before imputation\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After imputation\", batch\n",
    "  \n",
    "  assert_in_delta(0.5264289029370367, example1[\"features\"][\"ext_source_2\"], 1e-3, \"Fills in example 1\")\n",
    "  assert_in_delta(0.5264289029370367, example2[\"features\"][\"ext_source_2\"], 1e-3, \"Fills in example 2\")\n",
    "end\n",
    "\n",
    "test_22_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fab18185d2cbd7912a0bea58f5d8b73",
     "grade": true,
     "grade_id": "cell-1f4fbbc68f4e1328",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.12345}}, {\"features\"=>{\"ext_source_2\"=>0.4567}}]\n",
      "means in apply\n",
      "{\"ext_source_2\"=>0.5264289029370367}\n",
      "After imputation\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.12345, \"ext_source_2\"=>0.5264289029370367}}, {\"features\"=>{\"ext_source_2\"=>0.4567}}]\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "# Verifies that transformer calculates means for non-missing values\n",
    "def test_22_3()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  whitelist = %w(ext_source_2)\n",
    "  transform = MeanImputation.new whitelist  \n",
    "  transform.train sample_dataset\n",
    "  \n",
    "  example2 = {\"features\" => {\"ext_source_1\" => 0.12345}}\n",
    "  example3 = {\"features\" => {\"ext_source_2\" => 0.4567}}\n",
    "  \n",
    "  batch = [example2, example3]\n",
    "  \n",
    "  puts \"Before imputation\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After imputation\", batch\n",
    "  \n",
    "  assert_in_delta(0.12345, example2[\"features\"][\"ext_source_1\"], 1e-3, \"Does not alter other features\")\n",
    "  assert_in_delta(0.4567, example3[\"features\"][\"ext_source_2\"], 1e-3, \"Does not alter non-missing values\")\n",
    "end\n",
    "\n",
    "test_22_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d383bde4a4d0a5f9bc1c4859f8ada45a",
     "grade": false,
     "grade_id": "cell-bb78a69035c1a589",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2.3 (10 points)\n",
    "\n",
    "To demonstrate Binning, we will create a custom transformer for the ```days_birth``` feature in the dataset. Transform the feature value from negative days to positive years in 5-year increments, with a maximum age of 100 and minimum age of zero. Features are created as one-hot encoded values as follows:\n",
    "\n",
    "```ruby\n",
    "new_feature_name = pattern % binned_age\n",
    "```\n",
    "\n",
    "where the ```%``` operator for strings applies string formating like ```printf```. To keep everyone on the same page, define a bin $b$ given days $x$ as follows:\n",
    "\n",
    "$ b(x) = 5 \\times \\left\\lfloor \\frac{-x}{365 \\times 5} \\right \\rfloor$\n",
    "\n",
    "note that your implementation should further clip the bin to range $\\left [0,100 \\right ]$.\n",
    "\n",
    "Example: \n",
    "```\n",
    "[{\"features\"=>{\"days_birth\"=>-13505}}]\n",
    "After binning\n",
    "[{\"features\"=>{\"age_range_35\"=>1}}]\n",
    "```\n",
    "\n",
    "Notes:\n",
    "1. Skip any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0592d6f3b07214be36c58d59121e7204",
     "grade": false,
     "grade_id": "cell-2d58c55333b59dc4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":apply"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AgeRangeAsVector\n",
    "  def initialize; end\n",
    "  def train dataset; end\n",
    "  def apply(example_batch)\n",
    "    min_age = 0\n",
    "    max_age = 100\n",
    "    feature_name = \"days_birth\"\n",
    "    pattern = \"age_range_%d\"\n",
    "    example_batch.each do |item|\n",
    "      next if !(item[\"features\"][feature_name])\n",
    "      age=5*((-item[\"features\"][feature_name])/(365*5)).floor\n",
    "      \n",
    "      if age>100\n",
    "        age=100\n",
    "      end\n",
    "      \n",
    "      if age<0\n",
    "        age=0\n",
    "      end\n",
    "      item[\"features\"][pattern % [age]]=1\n",
    "      item[\"features\"].delete(feature_name)\n",
    "    end\n",
    "    \n",
    "    return example_batch\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7be44f9ad884aa014e3b1cf92054d51b",
     "grade": true,
     "grade_id": "cell-5d98a6e8c9ef6df0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before binning\n",
      "[{\"features\"=>{\"days_birth\"=>-13505}}]\n",
      "After binning\n",
      "[{\"features\"=>{\"age_range_35\"=>1}}]\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "# Verifies that binning returns a vector\n",
    "def test_23_1()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  binner = AgeRangeAsVector.new\n",
    "  \n",
    "  example1 = {\"features\" => {\"days_birth\" => -37 * 365}}\n",
    "  \n",
    "  batch = [example1]\n",
    "  \n",
    "  puts \"Before binning\", batch\n",
    "  binner.apply batch\n",
    "  puts \"After binning\", batch\n",
    "  \n",
    "  \n",
    "  assert_equal(1, example1[\"features\"][\"age_range_35\"], \"Bins example 1\")\n",
    "  assert_false(example1[\"features\"].has_key?(\"days_birth\"), \"Removes feature after transform\")\n",
    "  assert_equal(nil, example1[\"features\"][\"age_range_30\"], \"Bins example 1, in the 35 bin\")\n",
    "end\n",
    "\n",
    "test_23_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0977698db91e1fefdd59d74affd9f922",
     "grade": true,
     "grade_id": "cell-00d1a5c5b67be2c1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before binning\n",
      "[{\"features\"=>{\"days_birth\"=>-40000}}, {\"features\"=>{\"days_birth\"=>1000}}]\n",
      "After binning\n",
      "[{\"features\"=>{\"age_range_100\"=>1}}, {\"features\"=>{\"age_range_0\"=>1}}]\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "# Check that bins are clipped to min and max bins\n",
    "def test_23_2()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  binner = AgeRangeAsVector.new\n",
    "  \n",
    "  example2 = {\"features\" => {\"days_birth\" => -40000}}\n",
    "  example3 = {\"features\" => {\"days_birth\" => 1000}}\n",
    "  \n",
    "  batch = [example2, example3]\n",
    "  \n",
    "  puts \"Before binning\", batch\n",
    "  binner.apply batch\n",
    "  puts \"After binning\", batch\n",
    "  \n",
    "  \n",
    "  assert_equal(1, example2[\"features\"][\"age_range_100\"], \"Bins example 2, to max value\")\n",
    "  assert_equal(1, example3[\"features\"][\"age_range_0\"], \"Bins example 3, to min value\")\n",
    "end\n",
    "\n",
    "test_23_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0efe4bec1b7444dacb2da7bffb3b52d",
     "grade": false,
     "grade_id": "cell-f326ba1e344a652d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2.4 (10 points)\n",
    "\n",
    "Implement target averaging where a categorical feature is replaced with a numerical feature whose values are the average value of the target label for all examples with that feature. In this dataset, we are treating the target labels as either 0 or 1, so the average for the target label is an estimate of the probability of the class given the example has the feature value. \n",
    "\n",
    "In the ```train``` method, calculate the means for each possible feature value in the provided whitelist. For a feature named ```abc```, we will create a new feature called ```avg_abc```. \n",
    "\n",
    "The ```@means``` member variable is meant to be a two-dimensional hash defined as follows:\n",
    "```ruby\n",
    "{\"name_family_status\"=>{\n",
    "    \"Single / not married\"=>0.09486931268151017, \n",
    "    \"Married\"=>0.06931390977443609, \n",
    "    \"Separated\"=>0.07191011235955057, \n",
    "    \"Civil marriage\"=>0.093841642228739, \n",
    "    \"Widow\"=>0.06666666666666667\n",
    "    }, \n",
    "\"code_gender\"=>{\n",
    "    \"M\"=>0.09155261915998113, \n",
    "    \"F\"=>0.06855373728438743\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Notes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a751f62374a44b6ab02f706494da7bda",
     "grade": false,
     "grade_id": "cell-e4e1142795681537",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":train"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TargetAveraging\n",
    "  attr_reader :means\n",
    "  \n",
    "  def initialize feature_names\n",
    "    @means = Hash.new {|h,k| h[k] = Hash.new {|h,k| h[k] = 0}}\n",
    "    @feature_names = feature_names\n",
    "    @pattern = \"avg_%s\"\n",
    "    @total=Hash.new {|h,k| h[k] = Hash.new {|h,k| h[k] = 0}}\n",
    "  end\n",
    "  \n",
    "  def train dataset   \n",
    "    \n",
    "    dataset[\"data\"].each do |item|\n",
    "      item[\"features\"].each do |key,array|\n",
    "        if (array.is_a? (String))\n",
    "          @total[key][array]+=1.0\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "    \n",
    "    dataset[\"data\"].each do |item|\n",
    "      item[\"features\"].each do |key,array|\n",
    "        if (array.is_a? (String)) and item[\"label\"]==1 and @feature_names.include? key\n",
    "          @means[key][array]+=1.0/(@total[key][array])\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "    \n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be893b70d7e71e394dded2bd2568bbdc",
     "grade": true,
     "grade_id": "cell-3c834452ce773734",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means\n",
      "{\"code_gender\"=>{\"M\"=>0.09155261915998138, \"F\"=>0.06855373728438752}, \"name_family_status\"=>{\"Single / not married\"=>0.0948693126815103, \"Civil marriage\"=>0.09384164222873895, \"Married\"=>0.06931390977443627, \"Separated\"=>0.07191011235955051, \"Widow\"=>0.06666666666666667}}\n"
     ]
    }
   ],
   "source": [
    "### TEST ###\n",
    "# Verifies that transformer calculates means for non-missing values\n",
    "def test_24_1()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  lookup = TargetAveraging.new %w(name_family_status code_gender)\n",
    "  lookup.train sample_dataset\n",
    "  means = lookup.means\n",
    "  puts \"Means\", means\n",
    "  \n",
    "  nfs_means = means[\"name_family_status\"]\n",
    "  assert_equal 5, nfs_means.size  \n",
    "  assert_in_delta(0.09384164, nfs_means[\"Civil marriage\"], 1e-2, \"Average for civil marriage\")\n",
    "  assert_in_delta(0.07191011, nfs_means[\"Separated\"], 1e-2, \"Average for Separated\")\n",
    "  \n",
    "  cg_means = means[\"code_gender\"]\n",
    "  assert_in_delta(0.09155261915998113, cg_means[\"M\"], 1e-2, \"Average for code_gender=M\")\n",
    "  assert_in_delta(0.06855373728438743, cg_means[\"F\"], 1e-2, \"Average for code_gender=F\")\n",
    "  \n",
    "end\n",
    "\n",
    "test_24_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c23af44eb279649a97a9e2033f74c6a0",
     "grade": false,
     "grade_id": "cell-bf4d0d182dbbbdee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, implement the ```apply``` method which removes the original categorical feature from the example and replaces it with the new feature name and its average.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Before target averaging\n",
    "[{\"features\"=>{\"name_family_status\"=>\"Civil marriage\"}}]\n",
    "After target averaging\n",
    "[{\"features\"=>{\"avg_name_family_status\"=>0.093841642228739}}]\n",
    "```\n",
    "\n",
    "Notes:\n",
    "1. Skip any missing values\n",
    "1. Skip any feature value not present in the means table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28faa5ae9093387c21ee3aa3de9b841b",
     "grade": false,
     "grade_id": "cell-2315bad4193570fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":apply"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TargetAveraging  \n",
    "  def apply(example_batch)\n",
    "    \n",
    "    example_batch.clone.each do |item|\n",
    "      item[\"features\"].clone.each do |key,array|\n",
    "        if (array.is_a? (String)) and (@feature_names.include? key)\n",
    "          new_key=\"avg_\"+key\n",
    "          item[\"features\"][new_key] = @means[key][array]\n",
    "          item[\"features\"].delete(key)\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "    \n",
    "    return example_batch\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20992328e95d833befa25c842bb84189",
     "grade": true,
     "grade_id": "cell-6d6081736487874d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before target averaging\n",
      "[{\"features\"=>{\"name_family_status\"=>\"Civil marriage\"}}]\n",
      "After target averaging\n",
      "[{\"features\"=>{\"avg_name_family_status\"=>0.09384164222873895}}]\n"
     ]
    }
   ],
   "source": [
    "def test_24_2()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = TargetAveraging.new %w(name_family_status)\n",
    "  transform.train sample_dataset\n",
    "  \n",
    "  example1 = {\"features\" => {\"name_family_status\" => \"Civil marriage\"}}\n",
    "  batch = [example1]\n",
    "  \n",
    "  puts \"Before target averaging\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After target averaging\", batch\n",
    "  \n",
    "  assert_in_delta(0.09384164, example1[\"features\"][\"avg_name_family_status\"], 1e-3, \"Fills in example 1\")\n",
    "  assert_false(example1[\"features\"].has_key?(\"name_family_status\"), \"Removes previous feature name\")\n",
    "end\n",
    "\n",
    "test_24_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8fc3295042077147e5024a35a861412",
     "grade": true,
     "grade_id": "cell-e054b1a6e8f1e27f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before target averaging\n",
      "[{\"features\"=>{\"name_family_status\"=>\"Separated\", \"ext_source_1\"=>0.212}}]\n",
      "After target averaging\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.212, \"avg_name_family_status\"=>0.07191011235955051}}]\n"
     ]
    }
   ],
   "source": [
    "def test_24_3()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = TargetAveraging.new %w(name_family_status)\n",
    "  transform.train sample_dataset\n",
    "  \n",
    "  example2 = {\"features\" => {\"name_family_status\" => \"Separated\", \"ext_source_1\" => 0.212}}\n",
    "  \n",
    "  batch = [example2]\n",
    "  \n",
    "  puts \"Before target averaging\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After target averaging\", batch\n",
    "  \n",
    "  assert_in_delta(0.07191011, example2[\"features\"][\"avg_name_family_status\"], 1e-3, \"Fills in example 2\")\n",
    "  assert_in_delta(0.212, example2[\"features\"][\"ext_source_1\"], 1e-3, \"Does not alter other features\")\n",
    "end\n",
    "\n",
    "test_24_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dbb4dd5c3ef7db9116f4eb99022bad46",
     "grade": false,
     "grade_id": "cell-a30e968867736208",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2.5 (10 points)\n",
    "\n",
    "Implement one-hot encoding. Given an array of categorical feature names, introduce new features for each possible value. Each new feature should have a value of 1. Do not add any features for missing features or for values which are not present in the dataset. There is no separate ```train``` step.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Before one hot encoding\n",
    "[{\"features\"=>{\"name_family_status\"=>\"Civil marriage\"}}]\n",
    "After one hot encoding\n",
    "[{\"features\"=>{\"name_family_status=Civil marriage\"=>1.0}}]\n",
    "```\n",
    "\n",
    "Notes:\n",
    "1. Examples are altered in place and do not change anything outside the provided list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf6857047eddd16fc34d3497b1e4ab62",
     "grade": false,
     "grade_id": "cell-b7fa864ad3a572ee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":apply"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OneHotEncoding\n",
    "  def initialize feature_names\n",
    "    @feature_names = feature_names\n",
    "    @pattern = \"%s=%s\"\n",
    "  end\n",
    "  \n",
    "  def train dataset; end\n",
    "  \n",
    "  def apply(example_batch)\n",
    "    \n",
    "\n",
    "    example_batch.clone.each do |item|\n",
    "      @feature_names.each do |feature|\n",
    "        if (item[\"features\"][feature].is_a? (String))\n",
    "          new_key=feature+\"=\"+item[\"features\"][feature]\n",
    "          item[\"features\"][new_key] = 1.0\n",
    "          item[\"features\"].delete(feature)\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "    \n",
    "    return example_batch\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "299d4a0d7d862ac9801b9103babff67b",
     "grade": true,
     "grade_id": "cell-2843a16d1840e830",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before one hot encoding\n",
      "[{\"features\"=>{\"name_family_status\"=>\"Civil marriage\"}}]\n",
      "After one hot encoding\n",
      "[{\"features\"=>{\"name_family_status=Civil marriage\"=>1.0}}]\n"
     ]
    }
   ],
   "source": [
    "def test_25_1()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  lookup = OneHotEncoding.new %w(name_family_status)\n",
    "  \n",
    "  example1 = {\"features\" => {\"name_family_status\" => \"Civil marriage\"}}\n",
    "  \n",
    "  batch = [example1]\n",
    "  \n",
    "  puts \"Before one hot encoding\", batch\n",
    "  lookup.apply batch\n",
    "  puts \"After one hot encoding\", batch\n",
    "  \n",
    "  assert_in_delta(1.0, example1[\"features\"][\"name_family_status=Civil marriage\"], 1e-3, \"Fills in example 1\")\n",
    "  assert_false(example1[\"features\"].has_key?(\"name_family_status\"), \"Removes previous feature name\")\n",
    "  assert_false(example1[\"features\"].has_key?(\"name_family_status=Separated\"), \"Encodes only one value\")\n",
    "end\n",
    "\n",
    "test_25_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4003ba0fa669988aef7297b67ab346f5",
     "grade": true,
     "grade_id": "cell-2ebc50f2c6b85c83",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before one hot encoding\n",
      "[{\"features\"=>{\"name_family_status\"=>\"Separated\", \"ext_source_1\"=>0.212}}]\n",
      "After one hot encoding\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.212, \"name_family_status=Separated\"=>1.0}}]\n"
     ]
    }
   ],
   "source": [
    "def test_25_2()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  lookup = OneHotEncoding.new %w(name_family_status)\n",
    "  \n",
    "  example2 = {\"features\" => {\"name_family_status\" => \"Separated\", \"ext_source_1\" => 0.212}}\n",
    "  \n",
    "  batch = [example2]\n",
    "  \n",
    "  puts \"Before one hot encoding\", batch\n",
    "  lookup.apply batch\n",
    "  puts \"After one hot encoding\", batch\n",
    "  \n",
    "  assert_in_delta(1.0, example2[\"features\"][\"name_family_status=Separated\"], 1e-3, \"Fills in example 2\")\n",
    "  assert_in_delta(0.212, example2[\"features\"][\"ext_source_1\"], 1e-3, \"Does not alter other features\")\n",
    "end\n",
    "\n",
    "test_25_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4457fa12573b971f3114a90b20fa9963",
     "grade": false,
     "grade_id": "cell-b4c45c052b63af80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2.6 (10 points)\n",
    "\n",
    "Implement the logarithm transform for a numeric feature. One of the most common transforms. There are two edge cases. The feature should not take the value zero and should not be negative. In this case, we will apply the ```Math.log``` or natural logarithm and will not bother to check in the ```apply``` method about zero or negative values. Skip any example with a missing value. A new feature value ```log_%s``` is added to the example and the old feature is removed as a result of this transformation.\n",
    "\n",
    "Example:\n",
    "```\n",
    "Before log transform\n",
    "[{\"features\"=>{\"abc\"=>1000.0}}]\n",
    "After log transform\n",
    "[{\"features\"=>{\"log_abc\"=>6.907755278982137}}]\n",
    "```\n",
    "\n",
    "Notes: \n",
    "1. Examples are changed in place and do not alter any feature not in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec79eda4d0e8d54fcc5289cdecd692f0",
     "grade": false,
     "grade_id": "cell-00044307697c8e97",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":apply"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LogTransform\n",
    "  def initialize feature_names\n",
    "    @feature_names = feature_names\n",
    "    @pattern = \"log_%s\"\n",
    "  end\n",
    "  \n",
    "  def train dataset; end\n",
    "  \n",
    "  def apply(example_batch)\n",
    "    \n",
    "    example_batch.clone.each do |item|\n",
    "      @feature_names.each do |feature|\n",
    "\n",
    "        if (item[\"features\"][feature].is_a? (Numeric)) and item[\"features\"][feature]>0\n",
    "          new_key=\"log_\"+feature\n",
    "          item[\"features\"][new_key] = Math.log(item[\"features\"][feature])\n",
    "          item[\"features\"].delete(feature)\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "    return example_batch\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e57ddf8520799562dc582af03bd31cc",
     "grade": true,
     "grade_id": "cell-fefb27cc1ac7a63d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before log transform\n",
      "[{\"features\"=>{\"abc\"=>1000.0}}]\n",
      "After log transform\n",
      "[{\"features\"=>{\"log_abc\"=>6.907755278982137}}]\n"
     ]
    }
   ],
   "source": [
    "def test_26_1()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = LogTransform.new %w(abc)\n",
    "  \n",
    "  example1 = {\"features\" => {\"abc\" => 1000.0}}  \n",
    "  batch = [example1]\n",
    "  \n",
    "  puts \"Before log transform\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After log transform\", batch\n",
    "  \n",
    "  assert_in_delta(6.9077, example1[\"features\"][\"log_abc\"], 1e-3, \"Fills in example 1\")\n",
    "  assert_false(example1[\"features\"].has_key?(\"abc\"), \"Removes previous feature name\")\n",
    "end\n",
    "\n",
    "test_26_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8324a2f09a7833029a6140dc97b91c4f",
     "grade": true,
     "grade_id": "cell-5c79ffa7e435a111",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before log transform\n",
      "[{\"features\"=>{\"abc\"=>0.36787944117144233, \"ext_source_1\"=>0.212}}]\n",
      "After log transform\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.212, \"log_abc\"=>-1.0}}]\n"
     ]
    }
   ],
   "source": [
    "def test_26_2()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = LogTransform.new %w(abc)\n",
    "  \n",
    "  example2 = {\"features\" => {\"abc\" => Math.exp(-1), \"ext_source_1\" => 0.212}}  \n",
    "  batch = [example2]\n",
    "  \n",
    "  puts \"Before log transform\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After log transform\", batch\n",
    "  \n",
    "  assert_in_delta(-1, example2[\"features\"][\"log_abc\"], 1e-3, \"Fills in example 2\")\n",
    "  assert_in_delta(0.212, example2[\"features\"][\"ext_source_1\"], 1e-3, \"Does not alter other features\")\n",
    "end\n",
    "\n",
    "test_26_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b54dcd1c1381d5524340e081650c706",
     "grade": false,
     "grade_id": "cell-162f05d5255d5bb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2.7 (10 points)\n",
    "\n",
    "Implement $L_2$ normalization, which transforms all the numeric features in an example into a unit vector. First will we reuse our ```dot``` and ```norm``` methods from previous assignments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f443a29c511770db9983ba8b00d7c57a",
     "grade": false,
     "grade_id": "cell-624d058404001cd4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":norm"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dot x, w\n",
    "  sum=0\n",
    "  x.each do |key1, array1|\n",
    "    w.each do |key2, array2|\n",
    "      if key1==key2 then\n",
    "        sum+=array1*array2\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "  return sum\n",
    "\n",
    "end\n",
    "\n",
    "def norm w\n",
    "  sum=0\n",
    "  sum = Math.sqrt(dot(w,w))\n",
    "  return sum\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbe776d3a7bb6472a24bdddb7e51ef3a",
     "grade": true,
     "grade_id": "cell-428ff79032a9251e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Hidden test ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38a9f1553e748ec03cab8e53358b0944",
     "grade": false,
     "grade_id": "cell-8cdc4ea2abc6ae7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, we will implement the ```apply``` method. Skip any feature which is not numeric i.e., ```not x.is_a? Numeric``` in ruby.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Before transform\n",
    "[{\"features\"=>{\"abc\"=>1.0, \"bcd\"=>-1.0}}]\n",
    "After transform\n",
    "[{\"features\"=>{\"abc\"=>0.7071067811865475, \"bcd\"=>-0.7071067811865475}}]\n",
    "```\n",
    "\n",
    "Notes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "003f310719c8ba5672996885749bf0de",
     "grade": false,
     "grade_id": "cell-cf015f952219d64d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":apply"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class L2Normalize\n",
    "  def train dataset; end\n",
    "  def apply(example_batch)\n",
    "    \n",
    "    number=0\n",
    "    total=Hash.new {|h,k| h[k] = 0}\n",
    "    example_batch.clone.each do |item|\n",
    "      item[\"features\"].clone.each do |key,array|\n",
    "        if (array.is_a? (Numeric))\n",
    "          total[number]=(array)**2+total[number]\n",
    "        end\n",
    "      end\n",
    "      number+=1\n",
    "    end\n",
    "    \n",
    "    number=0\n",
    "    example_batch.clone.each do |item|\n",
    "      item[\"features\"].clone.each do |key,array|\n",
    "        if (array.is_a? (Numeric))\n",
    "          item[\"features\"][key]=array.to_f/((total[number])**0.5)\n",
    "        end\n",
    "      end\n",
    "      number+=1\n",
    "    end\n",
    "\n",
    "    return example_batch\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a703c7446fd73e8e4fa727cfcd594c77",
     "grade": true,
     "grade_id": "cell-8e1c187a77fe8283",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transform\n",
      "[{\"features\"=>{\"abc\"=>1.0, \"bcd\"=>-1.0}}]\n",
      "After transform\n",
      "[{\"features\"=>{\"abc\"=>0.7071067811865475, \"bcd\"=>-0.7071067811865475}}]\n"
     ]
    }
   ],
   "source": [
    "def test_27_2()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = L2Normalize.new\n",
    "  \n",
    "  example1 = {\"features\" => {\"abc\" => 1.0, \"bcd\" => -1.0}}\n",
    "  batch = [example1]\n",
    "  \n",
    "  puts \"Before transform\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After transform\", batch\n",
    "  \n",
    "  assert_in_delta(0.707, example1[\"features\"][\"abc\"], 1e-3, \"Fills in example 1\")\n",
    "  assert_in_delta(-0.707, example1[\"features\"][\"bcd\"], 1e-3, \"Fills in example 1 bcd\")\n",
    "end\n",
    "\n",
    "test_27_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9026a08e3640ae801e90d280a00d747",
     "grade": true,
     "grade_id": "cell-a1134d6f4ec023e5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transform\n",
      "[{\"features\"=>{\"abc\"=>1.0, \"bcd\"=>-1.0}}, {\"features\"=>{\"cdef\"=>-3.0, \"efg\"=>4.0}}]\n",
      "After transform\n",
      "[{\"features\"=>{\"abc\"=>0.7071067811865475, \"bcd\"=>-0.7071067811865475}}, {\"features\"=>{\"cdef\"=>-0.6, \"efg\"=>0.8}}]\n"
     ]
    }
   ],
   "source": [
    "def test_27_3()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = L2Normalize.new\n",
    "  \n",
    "  example1 = {\"features\" => {\"abc\" => 1.0, \"bcd\" => -1.0}}\n",
    "  example2 = {\"features\" => {\"cdef\" => -3.0, \"efg\" => 4.0}}\n",
    "  \n",
    "  batch = [example1, example2]\n",
    "  \n",
    "  puts \"Before transform\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After transform\", batch\n",
    "  \n",
    "  assert_in_delta(0.707, example1[\"features\"][\"abc\"], 1e-3, \"Fills in example 1\")\n",
    "  assert_in_delta(-0.707, example1[\"features\"][\"bcd\"], 1e-3, \"Fills in example 1 bcd\")\n",
    "  assert_in_delta(-0.6, example2[\"features\"][\"cdef\"], 1e-3, \"Fills in example 2\")\n",
    "  assert_in_delta(0.8, example2[\"features\"][\"efg\"], 1e-3, \"Fills in example 2 efg\")\n",
    "end\n",
    "\n",
    "test_27_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "207aca4aca2f57579f6125ad7e11620c",
     "grade": true,
     "grade_id": "cell-3173b54ff794dcb8",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transform\n",
      "[{\"features\"=>{\"abc\"=>1.0, \"bcd\"=>-1.0, \"string_feature\"=>\"STRING\"}}, {\"features\"=>{\"cdef\"=>-3.0, \"efg\"=>4.0}}]\n",
      "After transform\n",
      "[{\"features\"=>{\"abc\"=>0.7071067811865475, \"bcd\"=>-0.7071067811865475, \"string_feature\"=>\"STRING\"}}, {\"features\"=>{\"cdef\"=>-0.6, \"efg\"=>0.8}}]\n"
     ]
    }
   ],
   "source": [
    "def test_27_4()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = L2Normalize.new\n",
    "  \n",
    "  example1 = {\"features\" => {\"abc\" => 1.0, \"bcd\" => -1.0, \"string_feature\" => \"STRING\"}}\n",
    "  example2 = {\"features\" => {\"cdef\" => -3.0, \"efg\" => 4.0}}\n",
    "  \n",
    "  batch = [example1, example2]\n",
    "  \n",
    "  puts \"Before transform\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After transform\", batch\n",
    "  \n",
    "  assert_equal(\"STRING\", example1[\"features\"][\"string_feature\"], \"Ignores string features\")\n",
    "end\n",
    "\n",
    "test_27_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f7fe6d6cad69ae0236637a0387815e6",
     "grade": false,
     "grade_id": "cell-7d7dd7e6cac9a7ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2.8 (10 points)\n",
    "\n",
    "Implement downsampling, where we will filter out examples belonging to the negative class (```label <= 0```) according a provided probability. Rather than calculating a precise sampling rate as we do below, we commonly provide a nice round number like 10%. Therefore, we will not implement the ```train``` method. Instead we will update the ```@sampling_rate``` parameter in a separate function ```update_sampling_rate```.\n",
    "\n",
    "Notes:\n",
    "1. The sampling rate is **not** the class prior. It is the class ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51edc21255a4098b702e601085da82b2",
     "grade": false,
     "grade_id": "cell-a3ea6f4421ba4d3b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":update_sampling_rate"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DownsampleNegatives\n",
    "  attr_reader :sampling_rate\n",
    "  def initialize sampling_rate\n",
    "    @sampling_rate = sampling_rate\n",
    "  end\n",
    "  \n",
    "  def train dataset; end\n",
    "  \n",
    "  def update_sampling_rate dataset\n",
    "    \n",
    "    pos=0\n",
    "    neg=0\n",
    "    dataset[\"data\"].each do |item|\n",
    "      if item[\"label\"]>0 \n",
    "        pos+=1\n",
    "      else\n",
    "        neg+=1\n",
    "      end\n",
    "    end\n",
    "\n",
    "    @sampling_rate=pos.to_f/neg.to_f\n",
    "    \n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17983c80c4de917921eaf2bd104c68ee",
     "grade": true,
     "grade_id": "cell-5b1501d53769f730",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_28_1()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = DownsampleNegatives.new 0.0   \n",
    "  assert_equal 0.0, transform.sampling_rate\n",
    "  \n",
    "  transform.update_sampling_rate sample_dataset  \n",
    "  assert_in_delta(0.08212481668567705, transform.sampling_rate, 1e-3, \"Calculate the class ratio, not the class prior\")\n",
    "end\n",
    "\n",
    "test_28_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dda5634f9b8daa53710e82e107ee4e39",
     "grade": false,
     "grade_id": "cell-eb4875726756dca5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, we will implement the ```can_keep?``` method which returns a Boolean value indicating whether we can keep the example. To maintain consistent filtering for all students on this dataset, we will use deterministic sampling. Because every example in the dataset has a unique ID which does not depend on the data, we can use this to calculate the probability of keeping the example. Although less random, this a a very common practice in industry.\n",
    "\n",
    "\n",
    "Notes:\n",
    "1. Filters examples in place using the ```select!``` method in ruby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f15e168a8cbe4866187ac9ff993d6da3",
     "grade": false,
     "grade_id": "cell-25e636f6b42739df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":apply"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'digest'\n",
    "\n",
    "class DownsampleNegatives\n",
    "  def hashprob id\n",
    "    salt = \"eifjcchdivlbreckvgndlvkgdtdjnbcnjldelrgefcgt\"\n",
    "    (Digest::MD5.hexdigest(id.to_s + salt).to_i(16) % 100000).abs / 100000.0\n",
    "  end\n",
    "  \n",
    "  def can_keep? example\n",
    "    can_keep = true\n",
    "\n",
    "    if example[\"label\"]>0\n",
    "      return true\n",
    "    end\n",
    "    \n",
    "    if hashprob(example[\"id\"])>@sampling_rate \n",
    "      return false\n",
    "    end\n",
    "    return can_keep\n",
    "  end\n",
    "\n",
    "  def apply(example_batch)\n",
    "    return example_batch.select! {|example| can_keep? example}\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7cbd783c28295db426d081d739d5211",
     "grade": true,
     "grade_id": "cell-1a794022f2eb4993",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_28_2()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = DownsampleNegatives.new 0.0\n",
    "  \n",
    "  transform.update_sampling_rate sample_dataset\n",
    "  \n",
    "  example_to_keep = {\"id\" => 3, \"label\" => 0, \"features\" => {\"abc\" => 1.0}}\n",
    "  example_to_filter = {\"id\" => 0, \"label\" => 0, \"features\" => {\"abc\" => 1.0}}\n",
    "  example_pos = {\"id\" => 1, \"label\" => 1, \"features\" => {\"abc\" => 1.0}}  \n",
    "  \n",
    "  assert_true transform.can_keep?(example_to_keep), \"Keep example based on ID and label\"\n",
    "  assert_false transform.can_keep?(example_to_filter), \"Filter out example based on ID and label\"\n",
    "  assert_true transform.can_keep?(example_pos), \"Keep all positive examples\"\n",
    "end\n",
    "\n",
    "test_28_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89da6dcb4b2e1f771ef235f35926be16",
     "grade": false,
     "grade_id": "cell-e6b5dac51355637c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2.9 (10 points)\n",
    "\n",
    "Because we implemented feature transforms as a pipeline pattern, we can chaing together feature transforms into a pipeline. The ```FeatureTransformPipeline``` is itself a ```FeatureTransformer```, which supports ```train``` and ```apply```. In the ```train``` method, we will simply call ```train``` and ```apply``` on each transformer on each dataset. \n",
    "\n",
    "By calling train and apply, notice that the features will change in the middle of the pipeline. So, we can apply multiple transforms and expect that they will be built on top of each other's output. We are altering examples in place so we add new transforms which affect disjoint feature spaces.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Before transform\n",
    "[{\"features\"=>{\"ext_source_1\"=>0.7, \"ext_source_2\"=>0.2, \"amt_income_total\"=>1000.0}}]\n",
    "After transform\n",
    "[{\"features\"=>{\"ext_source_1\"=>0.1326016448876392, \"ext_source_2\"=>-0.24739172298070694, \"log_amt_income_total\"=>0.9597990097795109}}]\n",
    "\n",
    "```\n",
    "\n",
    "Notes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35beae00de9dffa2c6f5d180b2fc91ab",
     "grade": false,
     "grade_id": "cell-28d2691d1e4233ee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## class FeatureTransformPipeline\n",
    "  def initialize *transformers\n",
    "    @transformers = transformers\n",
    "  end\n",
    "  \n",
    "  def train dataset\n",
    "    puts \"beginnong of pipelline\"\n",
    "    number=0\n",
    "    @transformers.each do |item|\n",
    "      #puts \"number is \" \n",
    "      #puts number\n",
    "      transform=item\n",
    "      #puts \"data\"\n",
    "      #puts number\n",
    "      ##puts dataset[\"data\"][0..2]\n",
    "      transform.train dataset\n",
    "      #puts \"after train\"\n",
    "      #puts number\n",
    "      #puts dataset[\"data\"][0..2]\n",
    "      transform.apply dataset[\"data\"]\n",
    "      #puts \"after\"\n",
    "      #puts number\n",
    "      #puts dataset[\"data\"][0..2]\n",
    "      number+=1\n",
    "    end\n",
    "    \n",
    "    puts \"end of pipelline\"\n",
    "    \n",
    "  end\n",
    "  \n",
    "  def apply example_batch \n",
    "    return @transformers.inject(example_batch) do |u, transform|\n",
    "      u = transform.apply example_batch\n",
    "    end\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc1931862f4945842bd2edd13d8aa3fe",
     "grade": true,
     "grade_id": "cell-700e4e2f5ae07f6f",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginnong of pipelline\n",
      "end of pipelline\n",
      "Before transform\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.7, \"ext_source_2\"=>0.2, \"amt_income_total\"=>1000.0}}, {\"features\"=>{\"ext_source_1\"=>0.3, \"amt_income_total\"=>100000.0}}]\n",
      "After transform\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.1326016448876392, \"ext_source_2\"=>-0.24739172298070694, \"log_amt_income_total\"=>0.9597990097795109}}, {\"features\"=>{\"ext_source_1\"=>-0.08076041093856547, \"log_amt_income_total\"=>0.9967335431423154}}]\n"
     ]
    }
   ],
   "source": [
    "def test_29_1()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = FeatureTransformPipeline.new(\n",
    "    ZScoreTransformer.new(%w(ext_source_1 ext_source_2 ext_source_3)),\n",
    "    LogTransform.new(%w(amt_income_total)),\n",
    "    L2Normalize.new\n",
    "  )\n",
    "  \n",
    "  transform.train sample_dataset\n",
    "  \n",
    "  example1 = {\"features\" => {\"ext_source_1\" => 0.7, \"ext_source_2\" => 0.2, \"amt_income_total\" => 1000.0}}\n",
    "  example2 = {\"features\" => {\"ext_source_1\" => 0.3, \"amt_income_total\" => 100000.0}}\n",
    "  \n",
    "  batch = [example1, example2]\n",
    "  \n",
    "  puts \"Before transform\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After transform\", batch\n",
    "  \n",
    "  assert_in_delta(0.1326016448876392, example1[\"features\"][\"ext_source_1\"], 1e-3, \"Fills in example 1\")\n",
    "  assert_in_delta(0.9597990097795109, example1[\"features\"][\"log_amt_income_total\"], 1e-3, \"Fills in example 1 log_amt_income_total\")\n",
    "  assert_in_delta(-0.08076041093856547, example2[\"features\"][\"ext_source_1\"], 1e-3, \"Fills in example 2\")\n",
    "end\n",
    "\n",
    "test_29_1()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "102b941701bf49fb57aef0789ef4652d",
     "grade": false,
     "grade_id": "cell-1cfd4bc32c117abb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, we are ready to build a real ML data processing pipeline. The sample ```feature_transform_pipeline_29``` applies basic feature transforms. Other than testing all the code written here, little thought was put into the composition of the pipeline, so you should design your own in the next part of the final project. The result of this pipeline a fully numeric example that can be directly used in models.  \n",
    "\n",
    "Note that we are not adding ```DownsampleNegatives``` in this pipeline. Special care should be used to apply downsampling only in training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04b3900e27a3ca6f8f3e17fd37b90694",
     "grade": false,
     "grade_id": "cell-0714280fb0b92c48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":feature_transform_pipeline_29"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_transform_pipeline_29\n",
    "  FeatureTransformPipeline.new(\n",
    "    #ext_source\n",
    "    ZScoreTransformer.new(%w(ext_source_1 ext_source_2 ext_source_3)),\n",
    "    MeanImputation.new(%w(ext_source_2 ext_source_3)),\n",
    "    \n",
    "    #Treat amt_income_total and amt_credit as log normal\n",
    "    LogTransform.new(%w(amt_income_total amt_credit)),\n",
    "    ZScoreTransformer.new(%w(log_amt_income_total log_amt_credit)),\n",
    "      \n",
    "    #Imputation for commonarea_avg\n",
    "    MeanImputation.new(%w(commonarea_avg)),\n",
    "      \n",
    "    #One-hot encoded features\n",
    "    AgeRangeAsVector.new,      \n",
    "    OneHotEncoding.new(%w(name_family_status code_gender)),\n",
    "      \n",
    "    #Target Averages\n",
    "    TargetAveraging.new(%w(name_income_type flag_own_car flag_own_realty\n",
    "      name_family_status organization_type name_housing_type name_education_type)),      \n",
    "    L2Normalize.new\n",
    "  )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fa9a1018446bd1953cfc8cf2316268e",
     "grade": true,
     "grade_id": "cell-8938411b0c426f42",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginnong of pipelline\n",
      "means in apply\n",
      "{\"ext_source_2\"=>-6.0906627612613726e-15, \"ext_source_3\"=>-6.192312568763135e-15}\n",
      "means in apply\n",
      "{\"commonarea_avg\"=>0.04351730769230769}\n",
      "end of pipelline\n",
      "Before transform\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.7, \"ext_source_2\"=>0.2, \"amt_income_total\"=>1000.0}}, {\"features\"=>{\"ext_source_1\"=>0.3, \"amt_income_total\"=>100000.0}}]\n",
      "means in apply\n",
      "{\"ext_source_2\"=>-6.0906627612613726e-15, \"ext_source_3\"=>-6.192312568763135e-15}\n",
      "means in apply\n",
      "{\"commonarea_avg\"=>0.04351730769230769}\n",
      "After transform\n",
      "[{\"features\"=>{\"ext_source_1\"=>0.08875317278315571, \"ext_source_2\"=>-0.16558467546488206, \"ext_source_3\"=>-5.758789446700427e-16, \"log_amt_income_total\"=>-0.9821854258866999, \"commonarea_avg\"=>0.004047066576571951}}, {\"features\"=>{\"ext_source_1\"=>-0.7081029266295138, \"ext_source_2\"=>-4.623339689395529e-15, \"ext_source_3\"=>-4.700500682847904e-15, \"log_amt_income_total\"=>-0.7053361183296555, \"commonarea_avg\"=>0.03303339943711086}}]\n"
     ]
    }
   ],
   "source": [
    "def test_29_2()\n",
    "  sample_dataset = create_sample_dataset()\n",
    "  transform = feature_transform_pipeline_29()\n",
    "  transform.train sample_dataset\n",
    "  \n",
    "  \n",
    "  example1 = {\"features\" => {\"ext_source_1\" => 0.7, \"ext_source_2\" => 0.2, \"amt_income_total\" => 1000.0}}\n",
    "  example2 = {\"features\" => {\"ext_source_1\" => 0.3, \"amt_income_total\" => 100000.0}}\n",
    "  \n",
    "  batch = [example1, example2]\n",
    "  \n",
    "  puts \"Before transform\", batch\n",
    "  transform.apply batch\n",
    "  puts \"After transform\", batch\n",
    "  \n",
    "  assert_in_delta(0.08875317278315571, example1[\"features\"][\"ext_source_1\"], 1e-3, \"Fills in example 1\")\n",
    "  assert_in_delta(-0.9821854258866999, example1[\"features\"][\"log_amt_income_total\"], 1e-3, \"Fills in example 1 log_amt_income_total\")\n",
    "  assert_in_delta(0.004047066576571951, example1[\"features\"][\"commonarea_avg\"], 1e-3, \"Fills in example 1 commonarea_avg\")\n",
    "  assert_in_delta(-0.7081029266295138, example2[\"features\"][\"ext_source_1\"], 1e-3, \"Fills in example 2\")\n",
    "end\n",
    "\n",
    "test_29_2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38bb9beb0f6125a366965b602fa295b8",
     "grade": false,
     "grade_id": "cell-293837f2f164e791",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we will apply downsampling, which is used only during training. Notice the pattern we are using here:\n",
    "\n",
    "1. Create a ```feature_pipeline``` containing the feature transformations (no sampling) you want to use.\n",
    "1. Train this pipeline on your dataset\n",
    "1. Create a new dataset, which going to be your real training dataset\n",
    "1. Create a ```training_pipeline``` containing the pre-trained ```feature_pipeline``` and the sampling.\n",
    "1. Now only ```apply``` the training pipeline to your dataset.\n",
    "\n",
    "This pattern is useful in practice because we may use a small sample to test out features but want to apply all the transforms at the same time as running learning algorithms on on a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9660f4c37d8e108926c441bba8f0f4f",
     "grade": true,
     "grade_id": "cell-1fc9ec3b95c1e3e8",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginnong of pipelline\n",
      "beginnong of pipelline\n",
      "means in apply\n",
      "{\"ext_source_2\"=>-6.0906627612613726e-15, \"ext_source_3\"=>-6.192312568763135e-15}\n",
      "means in apply\n",
      "{\"commonarea_avg\"=>0.04351730769230769}\n",
      "end of pipelline\n",
      "means in apply\n",
      "{\"ext_source_2\"=>-6.0906627612613726e-15, \"ext_source_3\"=>-6.192312568763135e-15}\n",
      "means in apply\n",
      "{\"commonarea_avg\"=>0.04351730769230769}\n",
      "end of pipelline\n",
      "Before transform\n",
      "{\"label\"=>1, \"id\"=>100002, \"features\"=>{\"ext_source_1\"=>0.08303696739132256, \"ext_source_2\"=>0.2629485927471776, \"ext_source_3\"=>0.13937578009978951, \"amt_income_total\"=>202500, \"amt_credit\"=>406597.5, \"commonarea_avg\"=>0.0143, \"flag_own_car\"=>\"N\", \"flag_mobil\"=>1, \"days_birth\"=>-9461, \"organization_type\"=>\"Business Entity Type 3\", \"code_gender\"=>\"M\", \"flag_own_realty\"=>\"Y\", \"flag_emp_phone\"=>1, \"name_education_type\"=>\"Secondary / secondary special\", \"name_income_type\"=>\"Working\", \"name_family_status\"=>\"Single / not married\", \"name_housing_type\"=>\"House / apartment\"}}\n",
      "means in apply\n",
      "{\"ext_source_2\"=>-6.0906627612613726e-15, \"ext_source_3\"=>-6.192312568763135e-15}\n",
      "means in apply\n",
      "{\"commonarea_avg\"=>0.04351730769230769}\n",
      "After transform\n",
      "{\"label\"=>1, \"id\"=>100002, \"features\"=>{\"ext_source_1\"=>-0.4301494686897596, \"ext_source_2\"=>-0.3159733600945627, \"ext_source_3\"=>-0.4078409306124699, \"commonarea_avg\"=>0.0031440187995034397, \"flag_mobil\"=>0.21986145451073005, \"flag_emp_phone\"=>0.21986145451073005, \"log_amt_income_total\"=>0.12016761882377888, \"log_amt_credit\"=>-0.05116886915227946, \"age_range_25\"=>0.21986145451073005, \"flag_own_car=N\"=>0.21986145451073005, \"organization_type=Business Entity Type 3\"=>0.21986145451073005, \"code_gender=M\"=>0.21986145451073005, \"flag_own_realty=Y\"=>0.21986145451073005, \"name_education_type=Secondary / secondary special\"=>0.21986145451073005, \"name_income_type=Working\"=>0.21986145451073005, \"name_family_status=Single / not married\"=>0.21986145451073005, \"name_housing_type=House / apartment\"=>0.21986145451073005}}\n"
     ]
    }
   ],
   "source": [
    "def test_28_3()\n",
    "  sample_dataset = create_sample_dataset()  \n",
    "  feature_pipeline = FeatureTransformPipeline.new(feature_transform_pipeline_29())\n",
    "  feature_pipeline.train sample_dataset\n",
    "  \n",
    "  downsample = DownsampleNegatives.new(0.0)\n",
    "  downsample.update_sampling_rate sample_dataset\n",
    "\n",
    "  training_dataset = create_sample_dataset()\n",
    "  training_pipeline = FeatureTransformPipeline.new(feature_pipeline, downsample)\n",
    "  batch = training_dataset[\"data\"][0..199]\n",
    "  \n",
    "  puts \"Before transform\", batch[0]\n",
    "  sampled_batch = training_pipeline.apply batch\n",
    "  puts \"After transform\", sampled_batch[0]\n",
    "  \n",
    "  assert_equal 33, sampled_batch.size, \"Downsampling should remove several examples\"\n",
    "  assert_true(sampled_batch.all? {|e| e[\"features\"].size > 5}, \"At least 5 features\")\n",
    "  assert_true(sampled_batch[0][\"features\"].values.all? {|v| v.is_a? Numeric}, \"All features should be numeric\")\n",
    "  assert_in_delta(1.0, norm(sampled_batch[0][\"features\"]), 1e-3, \"Examples should be normalized to norm = 1\")\n",
    "end\n",
    "\n",
    "test_28_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "864b32c50acba62971d7098407c6fa54",
     "grade": false,
     "grade_id": "cell-f4e2040b1844cc44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3.1 (2 points)\n",
    "\n",
    "Use information gain to calculate the value of some features. You are free to explore how feature transforms affect information gain. \n",
    "\n",
    "First, copy all **your** implementations of these functions from previous assignments. We are only applying them to the dataset here. We will skip any missing features in the tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c169c03818308c4b5edf72ba9f75990",
     "grade": false,
     "grade_id": "cell-c21c0623e9b3043f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":class_distribution"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def class_distribution dataset\n",
    "  classes = Hash.new {|h,k| h[k] = 0}\n",
    "  dataset.each do |key,array|\n",
    "    classes[key[\"label\"]]=1+classes[key[\"label\"]]\n",
    "  end\n",
    "  \n",
    "  result={}\n",
    "  classes.each do |key,array|\n",
    "    result[key]=array.to_f/dataset.size.to_f\n",
    "  end\n",
    "  \n",
    "  return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9af28070c9db741294a0a495e47e95b",
     "grade": false,
     "grade_id": "cell-9ec6f94d29d04786",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":entropy"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy dist\n",
    "  ent=0\n",
    "  dist.each do |key,array|\n",
    "    if array==0\n",
    "      return 0.0\n",
    "    end\n",
    "    ent+=-array*Math.log(array)\n",
    "  end\n",
    "  \n",
    "  ent\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39951f8698dffd5a5282974f43d2eb15",
     "grade": true,
     "grade_id": "cell-29b0499002eb0974",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_31_1()\n",
    "  # Check that there are three classes\n",
    "  dataset = create_sample_dataset()\n",
    "  dist = class_distribution dataset[\"data\"]\n",
    "  h0 = entropy dist\n",
    "  assert_in_delta(0.2686201883261589, h0, 1e-3)\n",
    "end\n",
    "\n",
    "test_31_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "636bc17349caab1181c3bcb36cf01b4d",
     "grade": false,
     "grade_id": "cell-62e0c31dc3f17141",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3.2 (2 ponts)\n",
    "\n",
    "Reuse **your** implementation of information gain for categorical features and apply it to some of the features in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b076127b99cb28814e9debaf0d881bf9",
     "grade": false,
     "grade_id": "cell-955a1f9a89c8d966",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":information_gain"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def information_gain h0, splits\n",
    " size = Hash.new {|h,k| h[k] = 0}\n",
    "  sum = Hash.new {|h,k| h[k] = 0}\n",
    "  total=0\n",
    "  \n",
    "  splits.each do |key, array|\n",
    "    total+=array.size\n",
    "  end\n",
    "  \n",
    "  splits.each do |key, array|\n",
    "    sum[key]+=entropy(class_distribution(array))\n",
    "    size[key]=array.size\n",
    "  end\n",
    "  \n",
    "  result=0\n",
    "  \n",
    "  size.each do |key,array|\n",
    "    size[key]=size[key].to_f/total\n",
    "  end\n",
    "  \n",
    "  splits.each do |key, array|\n",
    "    result+=sum[key]*size[key]\n",
    "  end\n",
    "\n",
    "  return h0-result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50b5f7666512657edd5a5fbaeed5a336",
     "grade": true,
     "grade_id": "cell-b3fe0a3f89ec6adb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_32_1()\n",
    "  # Check that there are three classes\n",
    "  dataset = create_dataset $dev_db, \"select target, sk_id_curr, ext_source_1, flag_own_car from application_train where ext_source_1 <> ''\"\n",
    "  examples = dataset[\"data\"]\n",
    "  dist = class_distribution examples\n",
    "  h0 = entropy dist\n",
    "  \n",
    "  splits = examples.group_by {|row| row[\"features\"][\"flag_own_car\"]}\n",
    "  ig = information_gain h0, splits\n",
    "  assert_in_delta(0.0002206258541794237, ig, 1e-4)\n",
    "end\n",
    "\n",
    "test_32_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ec9cd85a8eb87a802313cd2b5fc377c",
     "grade": false,
     "grade_id": "cell-1956a349ec5fe9ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3.3 (2 points)\n",
    "\n",
    "Reuse **your** implemenation to find the best split point by information gain. Depending on how you implemented it, you may want to make it faster. This should finish within 30s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c447b9a1ce8d6f307f8162a9b45c51a8",
     "grade": false,
     "grade_id": "cell-4eaedad86202959c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":split_on_numeric_value"
      ]
     },
     "execution_count": 935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_split_point_numeric x, h0, fname\n",
    "  \n",
    "  x.each do |item|\n",
    "    if !item[\"features\"][fname]\n",
    "      item[\"features\"][fname]=0\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  sorted_values = x.collect {|r| r[\"features\"][fname]}.uniq.sort\n",
    "  min_sl = sorted_values.first\n",
    "  max_sl = sorted_values.last\n",
    "  \n",
    "  ig_max=-1\n",
    "  t_max=-1\n",
    "  \n",
    "  threshold = []\n",
    "  iG = []\n",
    "  h0 = entropy(class_distribution(x))\n",
    "  (0..sorted_values.size).step(20) do |t|\n",
    "    threshold << sorted_values[t]\n",
    "    iG << information_gain(h0, split_on_numeric_value(x, fname, sorted_values[t]))\n",
    "    if iG.last>ig_max\n",
    "      ig_max=iG.last\n",
    "      t_max=threshold.last\n",
    "    end\n",
    "  end\n",
    "  puts [t_max, ig_max]\n",
    "  return [t_max, ig_max]\n",
    "end\n",
    "\n",
    "\n",
    "def split_on_numeric_value x, k, v\n",
    "  splits={\"less than\"=>[], \"more than\"=>[]}\n",
    "\n",
    "  x.each do |item|\n",
    "    if item[\"features\"][k]\n",
    "      y=item[\"features\"][k]\n",
    "    else\n",
    "      y=0\n",
    "    end\n",
    "    if y<v\n",
    "      splits[\"less than\"]+=[item]\n",
    "    end\n",
    "    if y>=v\n",
    "      splits[\"more than\"]+=[item]\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  splits\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd35dfd0b3ef4c6166a0b1ca8e3b3c10",
     "grade": true,
     "grade_id": "cell-65968d0099e1be87",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4532045762368005, 0.009648282450843593]\n"
     ]
    },
    {
     "ename": "Test::Unit::AssertionFailedError",
     "evalue": "<0.009751743140812785> -/+ <0.0001> was expected to include\n<0.009648282450843593>.\n\nRelation:\n<<0.009648282450843593> < <0.009751743140812785>-<0.0001>[0.009651743140812786] <= <0.009751743140812785>+<0.0001>[0.009851743140812785]>",
     "output_type": "error",
     "traceback": [
      "\u001b[31mTest::Unit::AssertionFailedError\u001b[0m: <0.009751743140812785> -/+ <0.0001> was expected to include\n<0.009648282450843593>.\n\nRelation:\n<<0.009648282450843593> < <0.009751743140812785>-<0.0001>[0.009651743140812786] <= <0.009751743140812785>+<0.0001>[0.009851743140812785]>",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/test-unit-3.3.4/lib/test/unit/assertions.rb:59:in `block in assert_block'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/test-unit-3.3.4/lib/test/unit/assertions.rb:1635:in `_wrap_assertion'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/test-unit-3.3.4/lib/test/unit/assertions.rb:53:in `assert_block'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/test-unit-3.3.4/lib/test/unit/assertions.rb:877:in `block in assert_in_delta'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/test-unit-3.3.4/lib/test/unit/assertions.rb:1640:in `_wrap_assertion'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/test-unit-3.3.4/lib/test/unit/assertions.rb:869:in `assert_in_delta'",
      "<main>:8:in `test_33_1'",
      "<main>:11:in `<main>'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/iruby-0.4.0/lib/iruby/backend.rb:44:in `eval'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/iruby-0.4.0/lib/iruby/backend.rb:44:in `eval'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/iruby-0.4.0/lib/iruby/backend.rb:12:in `eval'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/iruby-0.4.0/lib/iruby/kernel.rb:90:in `execute_request'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/iruby-0.4.0/lib/iruby/kernel.rb:49:in `dispatch'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/iruby-0.4.0/lib/iruby/kernel.rb:38:in `run'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/iruby-0.4.0/lib/iruby/command.rb:110:in `run_kernel'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/iruby-0.4.0/lib/iruby/command.rb:40:in `run'",
      "/usr/local/rvm/gems/ruby-2.5.1/gems/iruby-0.4.0/bin/iruby:5:in `<top (required)>'",
      "/usr/local/rvm/gems/ruby-2.5.1/bin/iruby:23:in `load'",
      "/usr/local/rvm/gems/ruby-2.5.1/bin/iruby:23:in `<main>'",
      "/usr/local/rvm/gems/ruby-2.5.1/bin/ruby_executable_hooks:15:in `eval'",
      "/usr/local/rvm/gems/ruby-2.5.1/bin/ruby_executable_hooks:15:in `<main>'"
     ]
    }
   ],
   "source": [
    "def test_33_1()\n",
    "  # Check that there are three classes\n",
    "  dataset = create_sample_dataset()\n",
    "  examples = dataset[\"data\"]\n",
    "  dist = class_distribution examples\n",
    "  h0 = entropy dist\n",
    "  \n",
    "  t, ig = find_split_point_numeric examples, h0, \"ext_source_1\"\n",
    "  assert_in_delta(0.009751743140812785, ig, 1e-4)\n",
    "end\n",
    "\n",
    "test_33_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 2.5.1",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "2.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
